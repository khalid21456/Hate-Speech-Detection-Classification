{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0149c6d5-09b4-4b5c-a8a8-bdc02ac4c45e",
   "metadata": {},
   "source": [
    "## ***Importation des bibliothèques***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d89e00-d051-405a-9317-637e4063bee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: xgboost in c:\\users\\khalid\\appdata\\roaming\\python\\python312\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy in c:\\program files\\anaconda\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\program files\\anaconda\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15b95c9f-43f8-4039-94a9-13307eedd3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import csr_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "from collections import Counter\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import html\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c456cb3-4b71-4380-9f3c-ef12da34d530",
   "metadata": {},
   "source": [
    "## ***Exploration des données***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eceac5dd-7293-40f8-85eb-3f21a8c989d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6276a764-0844-449c-b883-c906c0829ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a469da4d-2211-4e48-8eed-28f65ca3811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Unnamed: 0\",\"count\",\"hate_speech\",\"offensive_language\",\"neither\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc18e62-f02d-41b4-b6c3-4c090563607b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "24778      1  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779      2  you've gone and broke the wrong heart baby, an...\n",
       "24780      1  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781      1              youu got wild bitches tellin you lies\n",
       "24782      2  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e21f988-9037-4645-812f-9e1c0e659a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dic = {0:\"hate_speech\",1:\"offensive_language\",2:\"neither\"}\n",
    "df[\"class\"]=df[\"class\"].map(map_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce0d1e-1ed6-43c2-96e3-f62146ff775f",
   "metadata": {},
   "source": [
    "## ***Data Cleaning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e150d3f3-9105-414b-8867-8a39abf4cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(message):\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7e8f60-def3-4a2a-88e4-b9f625ac3909",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"] = df[\"tweet\"].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5a70f1-3cc8-439d-9f94-cba792d7df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    # Unescape HTML entities (e.g., &amp; -> &, &#128536; -> emoji)\n",
    "    tweet = html.unescape(tweet)\n",
    "    # Remove mentions (@username)\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove hashtags (#hashtag)\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    # Remove emojis and non-ASCII characters\n",
    "    tweet = tweet.encode('ascii', 'ignore').decode('ascii')\n",
    "    # Remove special characters, punctuation (except sentence enders), and digits\n",
    "    tweet = re.sub(r'[^A-Za-z\\s]', '', tweet)\n",
    "    # Collapse multiple spaces into one\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet).strip()\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7559a293-9e8f-4773-8d76-5a9ba6b24bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03dc9a3d-95c2-4d96-8cb3-5825def7cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"] = df[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff9d70b3-6fbf-4791-b714-49c5acea2ef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neither</td>\n",
       "      <td>rt mayasolovely woman shouldnt complain cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt mleew boy dats coldtyga dwn bad cuffin dat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt urkindofbrand dawg rt sbabylife ever fuck b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt cganderson vivabased look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt shenikaroberts shit hear might true might f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>yous muthafin lie lifeasking pearls coreyemanu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>neither</td>\n",
       "      <td>youve gone broke wrong heart baby drove rednec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>youu got wild bitches tellin lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>neither</td>\n",
       "      <td>ruffled ntac eileen dahlia beautiful color com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class                                              tweet\n",
       "0                 neither  rt mayasolovely woman shouldnt complain cleani...\n",
       "1      offensive_language  rt mleew boy dats coldtyga dwn bad cuffin dat ...\n",
       "2      offensive_language  rt urkindofbrand dawg rt sbabylife ever fuck b...\n",
       "3      offensive_language           rt cganderson vivabased look like tranny\n",
       "4      offensive_language  rt shenikaroberts shit hear might true might f...\n",
       "...                   ...                                                ...\n",
       "24778  offensive_language  yous muthafin lie lifeasking pearls coreyemanu...\n",
       "24779             neither  youve gone broke wrong heart baby drove rednec...\n",
       "24780  offensive_language  young buck wanna eat dat nigguh like aint fuck...\n",
       "24781  offensive_language                  youu got wild bitches tellin lies\n",
       "24782             neither  ruffled ntac eileen dahlia beautiful color com...\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df61d4e-b476-491f-a333-e115fbb7959e",
   "metadata": {},
   "source": [
    "## ***Stemming***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "305ee4c8-c1e0-4525-810d-83f155d5c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "def stem(message):\n",
    "    stemmedArr = [porter.stem(term) for term in message.split(\" \")]\n",
    "    return ' '.join(stemmedArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "443ad9ff-8227-486a-8304-6fbc7c16c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71dee5ae-0957-4390-b4a2-513db4d32d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neither</td>\n",
       "      <td>rt mayasolov woman shouldnt complain clean hou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt mleew boy dat coldtyga dwn bad cuffin dat h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt urkindofbrand dawg rt sbabylif ever fuck bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt cganderson vivabas look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offensive_language</td>\n",
       "      <td>rt shenikarobert shit hear might true might fa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class                                              tweet\n",
       "0             neither  rt mayasolov woman shouldnt complain clean hou...\n",
       "1  offensive_language  rt mleew boy dat coldtyga dwn bad cuffin dat h...\n",
       "2  offensive_language  rt urkindofbrand dawg rt sbabylif ever fuck bi...\n",
       "3  offensive_language             rt cganderson vivabas look like tranni\n",
       "4  offensive_language  rt shenikarobert shit hear might true might fa..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2b8d31-6156-4da6-ae72-3aa9bb4c6b15",
   "metadata": {},
   "source": [
    "# **Continuous Skip-gram model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d93bbd-7be9-4873-8a5c-7f8d16098a79",
   "metadata": {},
   "source": [
    "## ***Build Vocabulary and Generate Skip-Gram Pairs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5edb38-ced9-456a-b871-42d33053c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2ddd6f4-2501-4946-9448-7be7a0e04eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ' '.join(texts).split()\n",
    "vocab = Counter(words)\n",
    "vocab_size = 10000  # top 10,000 words\n",
    "most_common = vocab.most_common(vocab_size-1)\n",
    "\n",
    "# Map words to integers\n",
    "word2idx = {w: i+1 for i, (w, _) in enumerate(most_common)}\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "\n",
    "def tokenize(text):\n",
    "    return [word2idx[word] for word in text.split() if word in word2idx]\n",
    "\n",
    "tokenized_texts = [tokenize(t) for t in texts]\n",
    "\n",
    "# Generate skip-gram pairs\n",
    "def generate_skip_gram_pairs(tokenized_sentences, window_size=2):\n",
    "    pairs = []\n",
    "    for tokens in tokenized_sentences:\n",
    "        for idx, center_word in enumerate(tokens):\n",
    "            context_range = list(range(max(0, idx - window_size), idx)) + \\\n",
    "                            list(range(idx + 1, min(len(tokens), idx + window_size + 1)))\n",
    "            for context_idx in context_range:\n",
    "                context_word = tokens[context_idx]\n",
    "                pairs.append((center_word, context_word))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_skip_gram_pairs(tokenized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2480f-c13c-456a-a75e-102095677e2c",
   "metadata": {},
   "source": [
    "## ***Prepare Data for TensorFlow***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cfcf785-1fc8-4a63-8791-0f45b0227fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(pairs, batch_size):\n",
    "    batch = random.sample(pairs, batch_size)\n",
    "    x = np.array([i for i, j in batch])\n",
    "    y = np.array([[j] for i, j in batch])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed402f5f-2819-4cf3-b8ec-944d07bbe6cb",
   "metadata": {},
   "source": [
    "## ***Define Skip-Gram Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71185dd3-8e03-498b-b01d-4f6c7f78a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "class SkipGramModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embed = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "model = SkipGramModel(vocab_size, embedding_dim)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b9dba-e2ad-4c11-9267-1a8e7e723447",
   "metadata": {},
   "source": [
    "## ***Train the Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb9b33e0-34c0-4cdb-837e-f8dcac6d6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "#epochs = 5\n",
    "#batch_size = 512\n",
    "#steps_per_epoch = 1000\n",
    "\n",
    "#for epoch in range(epochs):\n",
    "#    epoch_loss = 0\n",
    "#    for step in range(steps_per_epoch):\n",
    "#        x_batch, y_batch = generate_batch(pairs, batch_size)\n",
    "#        loss = model.train_on_batch(x_batch, y_batch)\n",
    "#        epoch_loss += loss\n",
    "#    print(f'Epoch {epoch+1}, Loss: {epoch_loss / steps_per_epoch}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e558208-8df1-4dca-b76b-b89b5fcedfdc",
   "metadata": {},
   "source": [
    "## ***Visualize Word Embeddings In Two Dimensions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f4e2fb3-7eba-47c6-a955-6c386741e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights\n",
    "embeddings = np.load('skipgram_embeddings.npy')\n",
    "embeddings = model.embed.get_weights()[0]\n",
    "\n",
    "# Pick a few words to visualize\n",
    "words_to_visualize = ['hate', 'love', 'kill', 'peace', 'fight']\n",
    "word_ids = [word2idx[w] for w in words_to_visualize if w in word2idx]\n",
    "\n",
    "for i, word_id in enumerate(word_ids):\n",
    "    vec = embeddings[word_id]\n",
    "    plt.scatter(vec[0], vec[1])\n",
    "    plt.text(vec[0], vec[1], words_to_visualize[i])\n",
    "plt.title('2D projection (only 2 dims shown)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cebacbb5-b7fb-48b3-895c-feadf5f0ddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n",
      "[-0.02848216  0.00400998 -0.03258134 -0.04974265  0.00207678  0.02484879\n",
      "  0.03113591 -0.00340078  0.00696534 -0.00292827 -0.04801117  0.02816404\n",
      " -0.01797894 -0.0195039  -0.01075071 -0.04995915  0.02681008 -0.00748922\n",
      " -0.02029742 -0.01303394 -0.03315737 -0.04590987 -0.01173951 -0.04502933\n",
      "  0.00965339  0.00400305  0.04076019 -0.01129614 -0.01013052  0.03318813\n",
      " -0.03019115  0.04862919  0.03768841 -0.0138522   0.04247582 -0.02034836\n",
      " -0.0272624   0.02495494  0.02386754 -0.0397911   0.0330441  -0.00070839\n",
      "  0.03407531 -0.02472837 -0.00889399 -0.00569149  0.0381316   0.03481778\n",
      "  0.01629115  0.03324561 -0.01976572 -0.03163081 -0.03177797  0.0226329\n",
      "  0.02272067 -0.01123648  0.04049429  0.00278439 -0.02448131  0.03498909\n",
      "  0.04240072  0.04180335  0.04316416  0.032443   -0.00954914 -0.04092628\n",
      "  0.00171892 -0.04406951  0.03671697  0.01783389  0.00139958  0.00457359\n",
      " -0.00527228  0.03302393 -0.04062376  0.01317779 -0.02013574  0.02377847\n",
      "  0.04156587 -0.00905819  0.02947456 -0.03318652 -0.01943955 -0.00367125\n",
      "  0.03432615 -0.02460798  0.02784859 -0.04051399  0.03590106 -0.04858372\n",
      " -0.03371741 -0.00070287 -0.03196668  0.00934897 -0.04684535 -0.0116209\n",
      " -0.02129763  0.0054175   0.04392871  0.03406913  0.0256863  -0.01944648\n",
      "  0.03244588  0.00830505  0.01178939 -0.02911764  0.01707694  0.02069906\n",
      " -0.01222699  0.00605987 -0.01538805  0.02387038  0.03169825  0.01924397\n",
      "  0.01017217 -0.02206194  0.00264873  0.04818144  0.02522243 -0.04063312\n",
      "  0.02758006  0.03113982 -0.0466383   0.01793475  0.02406322  0.00180085\n",
      " -0.0414484   0.02043326]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4b8434-15d4-4d9e-84ad-175053801462",
   "metadata": {},
   "source": [
    "## ***Save Embeddings***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1c325-4c37-4b5d-be00-7ff4846c22a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('skipgram_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8b8c8-4c9f-40af-984c-cdce2452e15f",
   "metadata": {},
   "source": [
    "## ***Evaluate Word Similarity***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70d8b21c-95c8-4980-b53a-bdaf4e58b754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dislik', 0.69293946), ('nofakingg', 0.68656343), ('tiemyduragboo', 0.6669945), ('dumbest', 0.6529794), ('mayormcginn', 0.64533913)]\n"
     ]
    }
   ],
   "source": [
    "def most_similar(word, top_n=5):\n",
    "    if word not in word2idx:\n",
    "        return []\n",
    "    word_vec = embeddings[word2idx[word]]\n",
    "    similarities = np.dot(embeddings, word_vec) / (\n",
    "        np.linalg.norm(embeddings, axis=1) * np.linalg.norm(word_vec) + 1e-10\n",
    "    )\n",
    "    nearest = np.argsort(similarities)[-top_n-1:-1][::-1]\n",
    "    return [(idx2word.get(i, 'UNK'), similarities[i]) for i in nearest]\n",
    "\n",
    "print(most_similar('hate'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1dd5c-6d08-482f-9803-3ae9b634fb44",
   "metadata": {},
   "source": [
    "## ***Prepare Sentence Vectors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb303cb0-856c-424e-91ff-bc1ea4043e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert sentence to embedding by averaging word vectors\n",
    "def sentence_to_vec(sentence, word2idx, embeddings):\n",
    "    tokens = [word2idx[word] for word in sentence.split() if word in word2idx]\n",
    "    if not tokens:\n",
    "        return np.zeros(embeddings.shape[1])  # return zero vector for empty case\n",
    "    return np.mean(embeddings[tokens], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e494e1d-8aa0-458e-9812-ac08974de9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to all samples\n",
    "df['vector'] = df['tweet'].apply(lambda x: sentence_to_vec(x, word2idx, embeddings))\n",
    "X = np.vstack(df['vector'].values)\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97ba64b-1edf-4d27-ad13-6faf98f53fcb",
   "metadata": {},
   "source": [
    "## ***Split The Data Into Train and Test Sets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f71ffa32-d228-4576-ba8e-b78cb8953bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fde945-fd45-404b-b977-4e3bfdd45880",
   "metadata": {},
   "source": [
    "## ***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "42069138-5abd-4baf-a3b1-b564ef28696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fba075a-eec9-4e2d-8336-d9521c6c9e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7908540685944856\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       hate_speech       0.22      0.65      0.32       429\n",
      "           neither       0.73      0.87      0.80      1249\n",
      "offensive_language       0.97      0.78      0.87      5757\n",
      "\n",
      "          accuracy                           0.79      7435\n",
      "         macro avg       0.64      0.77      0.66      7435\n",
      "      weighted avg       0.89      0.79      0.82      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fff1e9-6aa5-4bf7-b823-2c8535ce7a29",
   "metadata": {},
   "source": [
    "## ***Support Vector Machine Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26519c35-da1e-4cad-a275-a5d0054160dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', class_weight='balanced', probability=True).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "142c1e0d-c2cf-452a-b26b-db4dcd9e8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7905850706119704\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       hate_speech       0.21      0.65      0.32       429\n",
      "           neither       0.73      0.88      0.80      1249\n",
      "offensive_language       0.97      0.78      0.87      5757\n",
      "\n",
      "          accuracy                           0.79      7435\n",
      "         macro avg       0.64      0.77      0.66      7435\n",
      "      weighted avg       0.89      0.79      0.82      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363545c-449e-4c33-8758-c4d7ebbf8557",
   "metadata": {},
   "source": [
    "## ***Gaussian Naive Bais***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b133653e-9f58-403d-b445-4597ae1a1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9ab9b47-9382-4158-9a01-0e7a62b5c207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8162743779421654\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "       hate_speech       0.23      0.46      0.31       429\n",
      "           neither       0.70      0.78      0.74      1249\n",
      "offensive_language       0.94      0.85      0.89      5757\n",
      "\n",
      "          accuracy                           0.82      7435\n",
      "         macro avg       0.63      0.69      0.65      7435\n",
      "      weighted avg       0.86      0.82      0.83      7435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb_clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531b64f-c06b-45f6-9832-56cb82dd5cb4",
   "metadata": {},
   "source": [
    "## ***Random Forrest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01883d62-0912-4afe-b0e3-259c491dad54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878009414929388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,  # Number of trees in the forest\n",
    "    max_depth=None,    # Maximum depth of the trees\n",
    "    min_samples_split=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "predicted = rf_clf.predict(X_test)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "print(f\"Accuracy: {np.mean(predicted == y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c18feb-484d-47a6-9b8f-31ad826f1b25",
   "metadata": {},
   "source": [
    "## ***LSTM (Long short-term memory)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca935fe6-f715-4a4d-b4ac-f6c5bf823b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embeddings  # shape: (vocab_size, embedding_dim)\n",
    "vocab_size, embedding_dim = embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "324b2791-55d4-4bb5-9426-feb611ce7133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - accuracy: 0.7720 - loss: -2.2041 - val_accuracy: 0.7862 - val_loss: -5.6840\n",
      "Epoch 2/5\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 67ms/step - accuracy: 0.7744 - loss: -7.4428 - val_accuracy: 0.7862 - val_loss: -10.2174\n",
      "Epoch 3/5\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 70ms/step - accuracy: 0.7761 - loss: -12.5659 - val_accuracy: 0.7862 - val_loss: -14.6950\n",
      "Epoch 4/5\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 68ms/step - accuracy: 0.7760 - loss: -16.1354 - val_accuracy: 0.7862 - val_loss: -19.2041\n",
      "Epoch 5/5\n",
      "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 70ms/step - accuracy: 0.7770 - loss: -20.6775 - val_accuracy: 0.7862 - val_loss: -23.7097\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,235,141</span> (16.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,235,141\u001b[0m (16.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411,713</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411,713\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,823,428</span> (10.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,823,428\u001b[0m (10.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))  # remove input_length\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "map_dic = {\"hate_speech\": 0, \"offensive_language\": 1, \"neither\": 2}\n",
    "y_mapped = np.vectorize(map_dic.get)(y_train)\n",
    "\n",
    "model.fit(X_train, y_mapped, epochs=5, batch_size=32, validation_split=0.1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b12b7e2b-02b1-4cf9-8c7a-9f4943147cab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI hate deepseek generation code\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Preprocess: tokenize and pad\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m seq \u001b[38;5;241m=\u001b[39m \u001b[43msentence_to_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43mword2idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#padded = pad_sequences(seq, maxlen=max_len)  # use same `max_len` used in training\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     11\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(seq)\n",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m, in \u001b[0;36msentence_to_vec\u001b[1;34m(sentence, word2idx, embeddings)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msentence_to_vec\u001b[39m(sentence, word2idx, embeddings):\n\u001b[1;32m----> 3\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m [word2idx[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43msentence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word2idx]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tokens:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# return zero vector for empty case\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# New input text\n",
    "text = [\"I hate deepseek generation code\"]\n",
    "\n",
    "# Preprocess: tokenize and pad\n",
    "seq = sentence_to_vec(text,word2idx,embeddings)\n",
    "#padded = pad_sequences(seq, maxlen=max_len)  # use same `max_len` used in training\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(seq)\n",
    "\n",
    "# Decode the predicted class\n",
    "class_names = [\"hate_speech\", \"offensive_language\", \"neither\"]\n",
    "predicted_class = class_names[np.argmax(pred)]\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f98860-24ab-4a6d-8e09-fb3d8b82a0c7",
   "metadata": {},
   "source": [
    "## ***XGBoost Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0d43f-f74b-47fd-9908-266a9708feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ***XGBoost Classifier***\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "from xgboost import XGBClassifier\n",
    "# Create and train the XGBoost model\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,   # Number of boosting rounds\n",
    "    learning_rate=0.1,  # Step size shrinkage used to prevent overfitting\n",
    "    max_depth=5,        # Maximum depth of a tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Make predictions on test set\n",
    "predicted_encoded = xgb_clf.predict(X_test)\n",
    "predicted = label_encoder.inverse_transform(predicted_encoded)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "print(f\"Accuracy: {np.mean(predicted == y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02eecfe-2ec6-48a3-8718-fcd9d0e2d9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3d2ea-76e6-4483-89d5-8c4f98b1e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4997ac-43f0-4982-9a06-3d577376f5ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
