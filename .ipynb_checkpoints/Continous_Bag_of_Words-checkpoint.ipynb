{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc1102b-1bf6-4caf-9e84-292f45117269",
   "metadata": {},
   "source": [
    "## ***Importation des bibliothèques***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ffd567-eae8-4320-88f9-24f28d94498c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Add imports for Word2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0fce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # Install XGBoost\n",
    "# %pip install xgboost\n",
    "\n",
    "# # Install TensorFlow\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae6f78-613e-47f4-b5d2-f842a27023ec",
   "metadata": {},
   "source": [
    "## ***Exploration des données***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cda4d64-9d2a-4271-accf-a59a243f2be9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:32:38.318932Z",
     "start_time": "2025-05-04T17:32:38.220735Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/hamzacharmaqe/Documents/ENSAM/S2/TextMining/Project/labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dabd76df-78ff-4daa-aac9-d8ac1111c1f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.512758Z",
     "start_time": "2025-05-04T17:09:25.476031Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a0f9d8-7ebe-4dcd-b8bd-3bc977eadb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.513758Z",
     "start_time": "2025-05-04T17:09:25.501555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f487f9-c5b9-4523-b8f8-3027e00144de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.528359Z",
     "start_time": "2025-05-04T17:09:25.540417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725ce8b7-2086-4824-89bc-3430dcbcb9e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.547286Z",
     "start_time": "2025-05-04T17:09:25.585491Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  hate_speech  offensive_language  neither  class  \\\n",
       "24778      3            0                   2        1      1   \n",
       "24779      3            0                   1        2      2   \n",
       "24780      3            0                   3        0      1   \n",
       "24781      6            0                   6        0      1   \n",
       "24782      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7023df-4b53-45b3-869e-453b9cf2b09b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.550377Z",
     "start_time": "2025-05-04T17:09:25.629810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   count               24783 non-null  int64 \n",
      " 1   hate_speech         24783 non-null  int64 \n",
      " 2   offensive_language  24783 non-null  int64 \n",
      " 3   neither             24783 non-null  int64 \n",
      " 4   class               24783 non-null  int64 \n",
      " 5   tweet               24783 non-null  object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d097b5fd-adde-4ed4-88e4-0ca87c4450df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.551184Z",
     "start_time": "2025-05-04T17:09:25.792562Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop([\"hate_speech\",\"offensive_language\",\"neither\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76f4592-82a9-4bd7-a7cc-7d80cb037c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.551441Z",
     "start_time": "2025-05-04T17:09:25.900903Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  class                                              tweet\n",
       "0      3      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      3      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      3      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      6      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d2b31c-e6e5-431c-8c9a-9c982e1ea4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.576441Z",
     "start_time": "2025-05-04T17:09:25.990474Z"
    }
   },
   "outputs": [],
   "source": [
    "map_dic = {0:\"hate_speech\",1:\"offensive_language\",2:\"neither\"}\n",
    "df[\"class\"]=df[\"class\"].map(map_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1453ef9-eb69-4557-a617-094a422cd223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.578831Z",
     "start_time": "2025-05-04T17:09:26.132405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>neither</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count               class  \\\n",
       "0      3             neither   \n",
       "1      3  offensive_language   \n",
       "2      3  offensive_language   \n",
       "3      3  offensive_language   \n",
       "4      6  offensive_language   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c7bb7e-396a-46df-bb51-93d0d9e99673",
   "metadata": {},
   "source": [
    "## ***Text Preprocessing***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df964ba-0cd4-4de2-9dc9-aab3a82a3c18",
   "metadata": {},
   "source": [
    "### **Removing Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b35b8bd-4bd0-4cc0-ba68-925c3fc0cb75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.580894Z",
     "start_time": "2025-05-04T17:09:26.318966Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(message):\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return ' '.join(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b71a131-b69c-4ba7-b8ab-46d81b969b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.594872Z",
     "start_time": "2025-05-04T17:09:26.413245Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "df[\"tweet\"] = df[\"tweet\"].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebcdb2c0-b43c-4df5-bb3d-84695aa31e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.597122Z",
     "start_time": "2025-04-30T21:35:25.823679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>neither</td>\n",
       "      <td>RT mayasolovely woman shouldnt complain cleani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>RT mleew17 boy dats coldtyga dwn bad cuffin da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>RT UrKindOfBrand Dawg RT 80sbaby4life ever fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>RT CGAnderson vivabased look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>RT ShenikaRoberts shit hear might true might f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count               class  \\\n",
       "0      3             neither   \n",
       "1      3  offensive_language   \n",
       "2      3  offensive_language   \n",
       "3      3  offensive_language   \n",
       "4      6  offensive_language   \n",
       "\n",
       "                                               tweet  \n",
       "0  RT mayasolovely woman shouldnt complain cleani...  \n",
       "1  RT mleew17 boy dats coldtyga dwn bad cuffin da...  \n",
       "2  RT UrKindOfBrand Dawg RT 80sbaby4life ever fuc...  \n",
       "3           RT CGAnderson vivabased look like tranny  \n",
       "4  RT ShenikaRoberts shit hear might true might f...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89ef1e4a-2784-42de-ae75-8ea4300b51f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.599327Z",
     "start_time": "2025-04-30T21:35:25.898648Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tweet\"] = df[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2e420-e0ee-4530-b8b1-40d9a513ea2f",
   "metadata": {},
   "source": [
    "### **Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70af3936-c3d2-4589-96ff-908f5e110c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.601988Z",
     "start_time": "2025-04-30T21:35:25.975429Z"
    }
   },
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "def stem(message):\n",
    "    stemmedArr = [porter.stem(term) for term in message.split(\" \")]\n",
    "    return ' '.join(stemmedArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03055773-f63c-447c-88ed-1d2759db146f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.603517Z",
     "start_time": "2025-04-30T21:35:26.057608Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a824d1dc-216c-40e7-a589-3b57948fd400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.605105Z",
     "start_time": "2025-04-30T21:35:27.917782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>you muthafin lie 8220lifeask 20pearl coreyeman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>3</td>\n",
       "      <td>neither</td>\n",
       "      <td>youv gone broke wrong heart babi drove redneck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>3</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>young buck wanna eat dat nigguh like aint fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>6</td>\n",
       "      <td>offensive_language</td>\n",
       "      <td>youu got wild bitch tellin lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>3</td>\n",
       "      <td>neither</td>\n",
       "      <td>ruffl ntac eileen dahlia beauti color combin p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count               class  \\\n",
       "24778      3  offensive_language   \n",
       "24779      3             neither   \n",
       "24780      3  offensive_language   \n",
       "24781      6  offensive_language   \n",
       "24782      3             neither   \n",
       "\n",
       "                                                   tweet  \n",
       "24778  you muthafin lie 8220lifeask 20pearl coreyeman...  \n",
       "24779  youv gone broke wrong heart babi drove redneck...  \n",
       "24780  young buck wanna eat dat nigguh like aint fuck...  \n",
       "24781                     youu got wild bitch tellin lie  \n",
       "24782  ruffl ntac eileen dahlia beauti color combin p...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a499d3-de4d-4d4f-a60c-965daa1c2f8a",
   "metadata": {},
   "source": [
    "## ***Feature Extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9360de9e-dda5-44b8-8d8e-acc1767367fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.611156Z",
     "start_time": "2025-04-30T21:35:28.100774Z"
    }
   },
   "outputs": [],
   "source": [
    "#X = df.drop(\"class\",axis=1)\n",
    "#y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc61fab-5c39-4733-ba67-7141f6728085",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.613458Z",
     "start_time": "2025-04-30T21:35:28.147524Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "\n",
    "train_set, test_set = train_test_split(df, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df1c80ab-7011-43f9-b39f-dd47a179c230",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.614453Z",
     "start_time": "2025-04-30T21:35:28.189006Z"
    }
   },
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "for train_index, test_index in split.split(df, df[\"class\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeb0174c-7490-4fa4-9730-2beb04b04cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.615108Z",
     "start_time": "2025-04-30T21:35:28.215097Z"
    }
   },
   "outputs": [],
   "source": [
    "X_strat_train_set = strat_train_set.drop(\"class\",axis=1)\n",
    "y_strat_train_set = strat_train_set[\"class\"]\n",
    "X_strat_test_set = strat_test_set.drop(\"class\",axis=1)\n",
    "y_strat_test_set = strat_test_set[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "690320c5-2910-41b6-bc00-8e6078783eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.620391Z",
     "start_time": "2025-04-30T21:35:28.239827Z"
    }
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_count = count_vect.fit_transform(X_strat_train_set.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bf8dd9-0d49-4036-af33-e33faa33aa0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.630254Z",
     "start_time": "2025-04-30T21:35:28.345043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17348, 28160)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5241ebf7-2b1d-45c2-b0d9-5cafa13ee6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.632869Z",
     "start_time": "2025-04-30T21:35:28.358877Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_count = count_vect.transform(X_strat_test_set.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "303e2985-3c11-4a36-bba6-f88e6e1dca0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.636883Z",
     "start_time": "2025-04-30T21:35:28.403874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7435, 28160)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0f4a2-0dd3-410d-816b-93fbba8468d6",
   "metadata": {},
   "source": [
    "## ***Continuous Bag of Words (CBOW)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2698d4fb-b37f-42d9-b3f3-6101a735578c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.639708Z",
     "start_time": "2025-04-30T21:35:28.429311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 28189\n",
      "Training vectors shape: (17348, 100)\n",
      "Test vectors shape: (7435, 100)\n"
     ]
    }
   ],
   "source": [
    "# Replace the \"TF-IDF (term frequency-inverse document frequency)\" section with:\n",
    "\n",
    "## ***Continuous Bag of Words (CBOW)***\n",
    "\n",
    "# First, we need to tokenize our tweets to prepare for CBOW\n",
    "def tokenize_tweet(tweet):\n",
    "    return tweet.split()\n",
    "\n",
    "# Tokenize the training and test set tweets\n",
    "X_strat_train_set['tokens'] = X_strat_train_set['tweet'].apply(tokenize_tweet)\n",
    "X_strat_test_set['tokens'] = X_strat_test_set['tweet'].apply(tokenize_tweet)\n",
    "\n",
    "# Create and train CBOW model (Word2Vec with sg=0)\n",
    "# sg=0 means CBOW model, sg=1 would be Skip-gram\n",
    "cbow_model = Word2Vec(\n",
    "    sentences=X_strat_train_set['tokens'],\n",
    "    vector_size=100,    # Dimension of word vectors\n",
    "    window=5,           # Context window size\n",
    "    min_count=1,        # Ignore words that appear less than this\n",
    "    workers=4,          # Number of processors to use\n",
    "    sg=0                # 0 = CBOW, 1 = Skip-gram\n",
    ")\n",
    "\n",
    "print(f\"Vocabulary size: {len(cbow_model.wv.key_to_index)}\")\n",
    "\n",
    "# Function to create document vectors by averaging word vectors\n",
    "def document_vector(tokens, model):\n",
    "    # Filter tokens that are in the vocabulary\n",
    "    valid_tokens = [token for token in tokens if token in model.wv]\n",
    "    \n",
    "    if not valid_tokens:\n",
    "        # Return zeros if no tokens are in vocabulary\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    # Calculate the mean of all word vectors in the document\n",
    "    return np.mean([model.wv[token] for token in valid_tokens], axis=0)\n",
    "\n",
    "# Create document vectors for training and test sets\n",
    "X_train_cbow = np.array([document_vector(tokens, cbow_model) for tokens in X_strat_train_set['tokens']])\n",
    "X_test_cbow = np.array([document_vector(tokens, cbow_model) for tokens in X_strat_test_set['tokens']])\n",
    "\n",
    "print(f\"Training vectors shape: {X_train_cbow.shape}\")\n",
    "print(f\"Test vectors shape: {X_test_cbow.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01431d4a-4390-405b-951e-2976a26fbac9",
   "metadata": {},
   "source": [
    "## ***Multinomial Naive Bais Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59ae0a7b-f993-4c16-964f-08b297d2775f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.648256Z",
     "start_time": "2025-04-30T21:35:29.622279Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(X_train_cbow, y_strat_train_set)\n",
    "\n",
    "# For testing with new tweets\n",
    "def preprocess_and_vectorize(tweet_text):\n",
    "    processed = process(tweet_text)\n",
    "    processed = processed.lower()\n",
    "    processed = stem(processed)\n",
    "    tokens = processed.split()\n",
    "    return document_vector(tokens, cbow_model).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b79506e-4755-4c5a-bab9-bda56a658ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.649555Z",
     "start_time": "2025-04-30T21:35:29.662226Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_test = [\"What a beautifull day summer\"]\n",
    "tweet_test_vector = preprocess_and_vectorize(tweet_test[0])\n",
    "predicted = clf.predict(tweet_test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7dd27cb-23f7-449c-83bb-059fb7dbf840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.650418Z",
     "start_time": "2025-04-30T21:35:29.683485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['offensive_language']\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4040f0b9-c09a-4a5c-b44a-ffad31f9ae49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.651267Z",
     "start_time": "2025-04-30T21:35:29.724443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714862138533961\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_test_cbow)\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d49b8-5651-4fc4-9a72-b37d4e23a1cb",
   "metadata": {},
   "source": [
    "## ***Logistic Regression Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6b1a6b9-aecb-4641-bbae-e6ab6b3a144a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.652854Z",
     "start_time": "2025-04-30T21:35:29.766387Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_clf = LogisticRegression().fit(X_train_cbow, y_strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7df3ac17-ac68-4a5a-ad6b-9f4576cbcdc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.654442Z",
     "start_time": "2025-04-30T21:35:33.348006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8329522528581036\n"
     ]
    }
   ],
   "source": [
    "predicted = reg_clf.predict(X_test_cbow)\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d7d05-c19a-49d8-9ace-b5726ae00ee8",
   "metadata": {},
   "source": [
    "## ***Support Vector Machine Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c903a5d2-9d86-4291-81df-80665564cfd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.655780Z",
     "start_time": "2025-04-30T21:35:33.400594Z"
    }
   },
   "outputs": [],
   "source": [
    "svc_clf = SVC().fit(X_train_cbow, y_strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35d873c4-0dd2-4a15-a4b9-87091c0f0229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.656624Z",
     "start_time": "2025-04-30T21:35:42.501041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7839946200403497\n"
     ]
    }
   ],
   "source": [
    "predicted = svc_clf.predict(X_test_cbow)\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b542a-09a7-4d16-9c19-28d929effeeb",
   "metadata": {},
   "source": [
    "## ***Gaussiane Naive Bias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2450c7c8-fc62-432c-a0cd-8c4378ccb192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.657449Z",
     "start_time": "2025-04-30T21:35:49.000725Z"
    }
   },
   "outputs": [],
   "source": [
    "gnb_clf = GaussianNB().fit(X_train_cbow, y_strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "981dd893-9dca-43bc-8bf5-092fbbb8a582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.657884Z",
     "start_time": "2025-04-30T21:35:49.041461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714862138533961\n"
     ]
    }
   ],
   "source": [
    "predicted = gnb_clf.predict(X_test_cbow)\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bae4e0",
   "metadata": {},
   "source": [
    "### ***Random Forest Classifier***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc122d28-5936-4dbc-b4a3-98133d54a97e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.658319Z",
     "start_time": "2025-04-30T21:35:49.119037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8425016812373907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=200,  # Number of trees in the forest\n",
    "    max_depth=None,    # Maximum depth of the trees\n",
    "    min_samples_split=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_clf.fit(X_train_cbow, y_strat_train_set)\n",
    "\n",
    "# Make predictions on test set\n",
    "predicted = rf_clf.predict(X_test_cbow)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09245802",
   "metadata": {},
   "source": [
    "## ***XGBoost Classifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b1ba0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66707c15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T17:31:56.659214Z",
     "start_time": "2025-04-30T21:36:23.765532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8443846671149966\n"
     ]
    }
   ],
   "source": [
    "## ***XGBoost Classifier***\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the string labels to integers\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_strat_train_set)\n",
    "y_test_encoded = label_encoder.transform(y_strat_test_set)\n",
    "\n",
    "# Create and train the XGBoost model\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=100,   # Number of boosting rounds\n",
    "    learning_rate=0.1,  # Step size shrinkage used to prevent overfitting\n",
    "    max_depth=5,        # Maximum depth of a tree\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_clf.fit(X_train_cbow, y_train_encoded)\n",
    "\n",
    "# Make predictions on test set\n",
    "predicted_encoded = xgb_clf.predict(X_test_cbow)\n",
    "predicted = label_encoder.inverse_transform(predicted_encoded)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "print(f\"Accuracy: {np.mean(predicted == y_strat_test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cc234",
   "metadata": {},
   "source": [
    "## ***Convolutional Neural Network (CNN)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1af54709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.7553 - loss: 0.6585\n",
      "Epoch 2/5\n",
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537us/step - accuracy: 0.7885 - loss: 0.5838\n",
      "Epoch 3/5\n",
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.8088 - loss: 0.5404\n",
      "Epoch 4/5\n",
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - accuracy: 0.8246 - loss: 0.5083\n",
      "Epoch 5/5\n",
      "\u001b[1m543/543\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.8236 - loss: 0.5041\n",
      "Neural Network Accuracy: 0.8272\n"
     ]
    }
   ],
   "source": [
    "## ***Convolutional Neural Network (CNN)***\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_strat_train_set)\n",
    "y_test_encoded = le.transform(y_strat_test_set)\n",
    "num_classes = len(le.classes_)\n",
    "y_train_categorical = to_categorical(y_train_encoded, num_classes=num_classes)\n",
    "y_test_categorical = to_categorical(y_test_encoded, num_classes=num_classes)\n",
    "\n",
    "# Create a simple neural network (instead of CNN since our data is already vectorized)\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_cbow.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    X_train_cbow, \n",
    "    y_train_categorical,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test_cbow, y_test_categorical, verbose=0)\n",
    "print(f\"Neural Network Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
